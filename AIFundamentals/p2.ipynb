{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some useful packages and libraries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from collections import deque\n",
    "import heapq\n",
    "import unittest\n",
    "from scipy import stats\n",
    "import copy as cp\n",
    "from time import time\n",
    "import math\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 1: Maximizing an Objective Function with a Genetic Algorithm \n",
    "\n",
    "Suppose we've lost the index card with our favorite cupcake recipe. We know the ingredients of the cake, but cannot remember the exact amount of each ingredient. We decide to use a genetic algorithm to generate the  ingredient amounts. With each iteration of the genetic algorithm, we bake the cupcakes and taste-test them. We achieve our goal and stop running the genetic algorithm when we get to the actual recipe: \n",
    "\n",
    "* 1 tsp salt \n",
    "* 3 tsp baking powder \n",
    "* 2 cups all-purpose flour \n",
    "* 1 cup butter \n",
    "* 1 cup granulated sugar \n",
    "* 4 large eggs\n",
    "* 1 tsp vanilla extract\n",
    "* 1 cup buttermilk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [1, 3, 2, 1, 1, 4, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example starting state for a member of our population might look like: $state = [1, 2, 100, 36, 60, 3, 5, 50]$\n",
    "\n",
    "### (1a) \n",
    "\n",
    "Write an objective function `def recipe_success(state)` that takes a single argument state, and returns the objective function value (fitness) of the state. The objective function should be maximized when a state reaches the target. You could for example define the fitness score of a particular state based on how far away each entry is from the target recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_success(state):\n",
    "    #max possible value for each ingredient is 100 for normalization \n",
    "    #who the hell would have 100 of each ingredient though...\n",
    "    #unless ur a baker or something? but then wouldnt you have the recipe for cupcakes memorized? Not the point stay focuesed.\n",
    "    diff = sum(abs(s - t) / 100 for s, t in zip(state, target))\n",
    "    fitness = 1 / (1 + diff)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usesd math library to set a relative tolerance of 1e-9 because the fitness score is a float.\n",
    "#Could have written tons of test cases, but due to how controlled env was figured I only need to test the two real possibilites.\n",
    "\n",
    "#Test case 1: State and target have the same length and same values\n",
    "state = [1, 3, 2, 1, 1, 4, 1, 1]\n",
    "expected_output = 1.0\n",
    "assert math.isclose(recipe_success(state), expected_output, rel_tol=1e-9), f\"Expected {expected_output}, but got {recipe_success(state)}\"\n",
    "print(\"Test case 1 passed\")\n",
    "\n",
    "#Test case 2: State and target have the same length and diff values\n",
    "state = [1, 3, 2, 1, 1, 4, 2, 2]\n",
    "diff_normalized = sum(abs(s - t) / 100 for s, t in zip(state, target))\n",
    "expected_output = 1 / (1 + diff_normalized)\n",
    "assert math.isclose(recipe_success(state), expected_output, rel_tol=1e-9), f\"Expected {expected_output}, but got {recipe_success(state)}\"\n",
    "print(\"Test case 2 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1b) \n",
    "\n",
    "Using our in class notebook \"Lecture 16 - Genetic Algorithms.ipynb\" as your guide, write a genetic algorithm that starts with a population of 100 randomly generated \"recipes/states/members\" and uses the objective function you wrote in **(1a)** to hopefully hit the target after a certain number of generations. \n",
    "\n",
    "Key components of your code:\n",
    "- Generate the initial population randomly from integers between 0 and 100 \n",
    "- Allow for mutations in your population with an overall probability of mutation set to p = 0.2\n",
    "- Choose 2 \"parents\" in the generation of each \"child\"\n",
    "- Choose a random split point at which to combine the two \"parents\"\n",
    "\n",
    "Run the algorithm for 50 iterations (\"generations\"). Do you hit your target? --> <span style=\"color:red\">NO</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_population = [[random.randint(0, 100) for _ in range(len(target))] for _ in range(200)] #change outer list to adjust population size\n",
    "mutation_probability = 0.4 #probability of mutation\n",
    "fitness_goal = 1.0  #exact match to target\n",
    "n_iter = 500 #number of iterations\n",
    "\n",
    "class problem:\n",
    "    def __init__(self, initial_population, objective_function, mutation_probability, fitness_goal):\n",
    "        self.population = initial_population\n",
    "        self.objective_function = objective_function\n",
    "        self.p_mutate = mutation_probability\n",
    "        self.fitness_goal = fitness_goal\n",
    "        self.n_pop = len(initial_population)\n",
    "        self.n_dna = len(initial_population[0])\n",
    "\n",
    "    def fitness(self):\n",
    "        performance = [self.objective_function(member) for member in self.population]\n",
    "        total = sum(performance)\n",
    "        p_reproduce = [perf / total for perf in performance]\n",
    "        return p_reproduce\n",
    "\n",
    "    def reproduce(self, parent1, parent2):\n",
    "        split = np.random.randint(low=1, high=self.n_dna)\n",
    "        child = parent1[:split] + parent2[split:]\n",
    "        return child\n",
    "\n",
    "    def mutate(self, child):\n",
    "        gene = np.random.randint(low=0, high=self.n_dna)\n",
    "        mutation_type = np.random.choice(['increment', 'decrement', 'randomize'])\n",
    "        if mutation_type == 'increment' and child[gene] < 100:\n",
    "            child[gene] += 1\n",
    "        elif mutation_type == 'decrement' and child[gene] > 0:\n",
    "            child[gene] -= 1\n",
    "        elif mutation_type == 'randomize':\n",
    "            child[gene] = np.random.randint(0, 101)\n",
    "        return child\n",
    "\n",
    "\n",
    "def genetic_algorithm(problem, n_iter):\n",
    "    for t in range(n_iter):\n",
    "        new_generation = []\n",
    "        \n",
    "        for k in range(problem.n_pop):\n",
    "            p_reproduce = problem.fitness()\n",
    "            ind_parents = np.random.choice(range(problem.n_pop), size=2, p=p_reproduce, replace=False)\n",
    "            parent1, parent2 = problem.population[ind_parents[0]], problem.population[ind_parents[1]]\n",
    "            \n",
    "            child = problem.reproduce(parent1, parent2)\n",
    "            \n",
    "            l_mutate = np.random.choice([True, False], p=[problem.p_mutate, 1-problem.p_mutate])\n",
    "            if l_mutate:\n",
    "                child = problem.mutate(child)\n",
    "            \n",
    "            new_generation.append(child)\n",
    "        \n",
    "        problem.population = new_generation\n",
    "        \n",
    "        performance = [problem.objective_function(member) for member in problem.population]\n",
    "        best_performance = max(performance)\n",
    "        best_member = problem.population[performance.index(best_performance)]\n",
    "        \n",
    "        if best_performance >= problem.fitness_goal:\n",
    "            print(f\"Goal achieved at generation {t+1}\")\n",
    "            return best_member, best_performance\n",
    "\n",
    "    print('Reached maximum number of iterations')\n",
    "    return best_member, best_performance\n",
    "\n",
    "\n",
    "\n",
    "#problem instance and prints\n",
    "cupcake_problem = problem(initial_population, recipe_success, mutation_probability, fitness_goal)\n",
    "best_recipe, best_fitness = genetic_algorithm(cupcake_problem, n_iter)\n",
    "print(f\"Output State: {best_recipe}\\nFitness: {best_fitness}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TARGET = [1, 3, 2, 1, 1, 4, 1, 1]\n",
    "\n",
    "\n",
    "FIRST RUN: (50gens, 100 pop, .2pm)\n",
    "- Reached maximum number of iterations\n",
    "- Output State: [5, 1, 10, 2, 9, 0, 13, 13]\n",
    "- Fitness: 0.6622516556291391\n",
    "\n",
    "SECOND RUN: (500gens, 100 pop, .2 pm)\n",
    "- Goal achieved at generation 449\n",
    "- Output State: [1, 3, 2, 1, 1, 4, 1, 1]\n",
    "- Fitness: 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1c)\n",
    "\n",
    "Report the following:\n",
    "- How many generations did it take to hit the goal? \n",
    "    - <span style=\"color:red\">449 on the second try</span>\n",
    "- If you change the initial population size to 200, does that change the number of generations it takes to achieve the goal recipe? \n",
    "    - <span style=\"color:red\">In theory yes, running 50 iterations with a 100 pop size I saw Fitness values of .5 to .8, running 50 iterations wiht a 200 pop size resulted in Fitness values of .8 to .98 </span>\n",
    "- If you change the probability of mutation, does that affect the number of generations it takes to achieve the goal recipe? How so?\n",
    "    - <span style=\"color:red\">For this problem landscape (500 iter and 200 pop), increasing it lessened the generations needed to reach the target goal. This peaked at .4 pm (check table below for average), then slowly lessened due to increassed disruption. Generally speaking though, it depends on the problem landscape such has fitness, population size, iteration, etc. For my space it allowed for enhanced exploration which helped with any premature convergance issues, but only up to a certain point. Dont take my numbers for exact truth though becasue I only ran each variation 3 times and only looked at .2 increments of PM, so its not exact on but there is an obvious trend. </span>\n",
    "\n",
    "\n",
    "Outcomes of different pop/mp values at 500 iterations:\n",
    "\n",
    "| Mutation Probability | Population Size | Fitness (3 Run Average) |\n",
    "|----------------------|-----------------|------------------|\n",
    "|         0.2          |       200       |      0.993        |\n",
    "|         0.4          |       200       |      1.000        | \n",
    "|         0.6          |       200       |      0.955        |\n",
    "|         0.8          |       200       |      0.928        |\n",
    "|         1            |       200       |      0.914        |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
